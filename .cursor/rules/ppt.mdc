---
description: 
globs: 
alwaysApply: true
---
# 機能要件定義書：プッシュツートーク型 リアルタイム音声対話システム

## 1. 概要

本システムは、ユーザーが明確な操作（録音開始/停止ボタンなど）によって音声入力の区間を指定し、リアルタイムで音声認識（ASR）を実行し、その結果を利用して応答生成や表示を行うことを目的とする。バックエンドではOpenAIの技術（Whisper等）の利用を想定する。

---

## 2. 機能要件一覧

### 2.1. 音声入力と制御 (個別ボタン方式)

* **FR-PTT-01 (改):** **【必須】** ユーザーは、特定のUI要素（例：「録音開始」ボタン）をクリック/タップすることにより、音声の録音およびシステムへの送信を開始できること。
* **FR-PTT-02 (改):** **【必須】** 「録音開始」操作が行われてから「録音停止」操作が行われるまでの間、システムはマイクからの音声を継続的にキャプチャし、リアルタイムで音声処理サービス（ASR等）へストリーミング送信すること。
* **FR-PTT-03 (改):** **【必須】** ユーザーが特定のUI要素（例：「録音停止」ボタン）をクリック/タップした際、システムは即座にマイクからの音声キャプチャとストリーミング送信を停止すること。
* **FR-PTT-04:** **【必須】** 「録音停止」操作時（FR-PTT-03 改）、システムは音声処理サービスに対し、ユーザーの発話が完了したこと（発話の区切り）を適切に通知すること。（これにより、ASRサービスが最終的な認識結果を確定できる）
* **FR-PTT-05:** **【推奨】** 「録音開始」から「録音停止」までの間に含まれる無音区間を検出し、不要な無音データを送信しないように最適化してもよい。（クライアントサイドでの簡易VAD併用）

### 2.2. 音声認識 (ASR)

* **FR-ASR-01:** **【必須】** ユーザーが指定した区間（FR-PTT-01 改 〜 FR-PTT-03 改）で入力された音声は、指定された音声認識エンジン（例：OpenAI Whisper）によってテキストに変換されること。
* **FR-ASR-02:** **【必須】** 音声認識は、「録音開始」から「録音停止」までの間、音声データがストリーミングで送られてくるのに合わせて、リアルタイムまたは低遅延で実行されること。
* **FR-ASR-03:** **【推奨】** 音声認識の途中結果（部分的な認識テキスト）を、ユーザーの発話中にリアルタイムで画面に表示すること。
* **FR-ASR-04:** **【必須】** 「録音停止」操作（FR-PTT-03 改）および発話終了通知（FR-PTT-04）の後、システムは最終的な認識結果テキストを確定し、利用可能にすること。
* **FR-ASR-05:** **【必須】** 音声認識エンジンは、クライアントからの発話終了通知（FR-PTT-04）と、サーバーサイドでのVAD（音声活動検出、特にEnd-pointing: 発話終了点の検出）ロジック（OpenAI VADドキュメント参照）を組み合わせて、最適な発話区切りを判断し、認識精度を高めること。

### 2.3. ユーザーインターフェース (UI)

* **FR-UI-01 (改):** **【必須】** ユーザーが音声録音の開始と停止を行うための、明確なUI要素（例：「録音開始」ボタンと「録音停止」ボタン）を提供すること。（※ボタンは状態によって表示/非表示が切り替わる、あるいは一つのボタンがトグルで状態変化するなど、具体的なUI実装は別途定義）
* **FR-UI-02:** **【必須】** システムが音声を録音・送信中であることをユーザーに視覚的にフィードバックすること（例：ボタンの状態変化、インジケーター表示、マイクアイコンの変化など）。
* **FR-UI-03:** **【必須】** 音声認識の結果（途中結果および最終結果）を画面上に表示すること。

### 2.4. （オプション）対話処理

* **FR-AGENT-01:** **【任意】** 最終的な認識結果テキスト（FR-ASR-04）を、後続の処理（例：AIエージェントへの入力、コマンド実行、単純な表示など）に利用できること。

### 2.5. （オプション）音声合成 (TTS)

* **FR-TTS-01:** **【任意】** システムからの応答（例：AIエージェントの返答）をテキストから音声に合成できること（例：OpenAI TTS）。
* **FR-TTS-02:** **【任意】** 合成された音声をユーザーに再生すること。

---

## 3. 補足

* OpenAIのリアルタイムVADドキュメントで言及されているVADは、主にサーバーサイドで「自然な発話の終わり」を検出するEnd-pointingの役割を担う。本要件の開始/停止ボタン方式はクライアントサイドでの「強制的な録音・送信の開始/終了」を制御するものであり、これらは連携して動作する。クライアントが「録音停止」操作をしてストリームを停止したことをサーバーサイドVADが検知し、最終的な発話区切りを判断する、といった流れになる。
* 遅延（Latency）に関する要件は非機能要件として別途定義することが望ましい（例：「録音停止操作から最終認識結果表示までの時間はXミリ秒以内」など）。